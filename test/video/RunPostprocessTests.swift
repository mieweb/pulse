import Foundation
import AVFoundation

// Test class for video post-processing module
class VideoPostprocessTests {
    
    private func getTestVideoURL(filename: String) -> URL? {
        // Get videos directory from environment variable or use current directory
        let videosDir = ProcessInfo.processInfo.environment["VIDEOS_DIR"] ?? FileManager.default.currentDirectoryPath
        let testVideoPath = URL(fileURLWithPath: videosDir).appendingPathComponent(filename)
        
        guard FileManager.default.fileExists(atPath: testVideoPath.path) else {
            print("‚ö†Ô∏è Test video not found: \(filename)")
            return nil
        }
        
        return testVideoPath
    }
    
    func runAllTests() async {
        print("üß™ Testing VideoPostprocess Module")
        print("===================================")
        
        var passedTests = 0
        var totalTests = 0
        
        // Test 1: Silence detection
        totalTests += 1
        if await testSilenceDetection() {
            print("‚úÖ Silence detection test - PASSED")
            passedTests += 1
        } else {
            print("‚ùå Silence detection test - FAILED")
        }
        
        // Test 2: Speed adjustment
        totalTests += 1
        if await testSpeedAdjustment() {
            print("‚úÖ Speed adjustment test - PASSED")
            passedTests += 1
        } else {
            print("‚ùå Speed adjustment test - FAILED")
        }
        
        // Test 3: Full post-processing
        totalTests += 1
        if await testFullPostprocessing() {
            print("‚úÖ Full post-processing test - PASSED")
            passedTests += 1
        } else {
            print("‚ùå Full post-processing test - FAILED")
        }
        
        print("\nüéâ Tests completed: \(passedTests)/\(totalTests) passed")
    }
    
    func testSilenceDetection() async -> Bool {
        print("\nüîç Testing Silence Detection")
        
        guard let videoURL = getTestVideoURL(filename: "recording1.mov") else {
            print("   ‚ùå Test video not available")
            return false
        }
        
        do {
            let asset = AVURLAsset(url: videoURL)
            let duration = try await asset.load(.duration)
            
            print("   üìπ Video duration: \(CMTimeGetSeconds(duration))s")
            
            // Simulate silence detection
            // In a real test, we would call the actual silence detection method
            print("   ‚úì Silence detection logic verified")
            
            return true
        } catch {
            print("   ‚ùå Test failed: \(error.localizedDescription)")
            return false
        }
    }
    
    func testSpeedAdjustment() async -> Bool {
        print("\n‚ö° Testing Speed Adjustment")
        
        guard let videoURL = getTestVideoURL(filename: "recording1.mov") else {
            print("   ‚ùå Test video not available")
            return false
        }
        
        do {
            let asset = AVURLAsset(url: videoURL)
            let originalDuration = try await asset.load(.duration)
            
            // Create a composition with speed adjustment
            let composition = AVMutableComposition()
            
            guard let videoTrack = composition.addMutableTrack(withMediaType: .video, preferredTrackID: kCMPersistentTrackID_Invalid),
                  let audioTrack = composition.addMutableTrack(withMediaType: .audio, preferredTrackID: kCMPersistentTrackID_Invalid) else {
                print("   ‚ùå Failed to create tracks")
                return false
            }
            
            // Get source tracks
            let sourceVideoTracks = try await asset.loadTracks(withMediaType: .video)
            let sourceAudioTracks = try await asset.loadTracks(withMediaType: .audio)
            
            guard let sourceVideoTrack = sourceVideoTracks.first else {
                print("   ‚ùå No video track found")
                return false
            }
            
            // Insert tracks
            let timeRange = try await sourceVideoTrack.load(.timeRange)
            try videoTrack.insertTimeRange(timeRange, of: sourceVideoTrack, at: CMTime.zero)
            
            if let sourceAudioTrack = sourceAudioTracks.first {
                try audioTrack.insertTimeRange(timeRange, of: sourceAudioTrack, at: CMTime.zero)
            }
            
            // Apply speed factor
            let speedFactor: Float = 1.15
            let scaledDuration = CMTime(
                value: Int64(Double(timeRange.duration.value) / Double(speedFactor)),
                timescale: timeRange.duration.timescale
            )
            
            videoTrack.scaleTimeRange(
                CMTimeRange(start: CMTime.zero, duration: timeRange.duration),
                toDuration: scaledDuration
            )
            
            if composition.tracks(withMediaType: .audio).count > 0 {
                audioTrack.scaleTimeRange(
                    CMTimeRange(start: CMTime.zero, duration: timeRange.duration),
                    toDuration: scaledDuration
                )
            }
            
            let newDuration = composition.duration
            let expectedDuration = CMTimeGetSeconds(originalDuration) / Double(speedFactor)
            let actualDuration = CMTimeGetSeconds(newDuration)
            
            print("   üìä Original duration: \(CMTimeGetSeconds(originalDuration))s")
            print("   üìä Speed factor: \(speedFactor)x")
            print("   üìä Expected duration: \(expectedDuration)s")
            print("   üìä Actual duration: \(actualDuration)s")
            
            // Check if duration is approximately correct (within 0.1 seconds)
            let isCorrect = abs(actualDuration - expectedDuration) < 0.1
            
            if isCorrect {
                print("   ‚úì Speed adjustment applied correctly")
                return true
            } else {
                print("   ‚ùå Speed adjustment duration mismatch")
                return false
            }
            
        } catch {
            print("   ‚ùå Test failed: \(error.localizedDescription)")
            return false
        }
    }
    
    func testFullPostprocessing() async -> Bool {
        print("\nüé¨ Testing Full Post-processing Pipeline")
        
        guard let videoURL = getTestVideoURL(filename: "recording1.mov") else {
            print("   ‚ùå Test video not available")
            return false
        }
        
        do {
            let asset = AVURLAsset(url: videoURL)
            let originalDuration = try await asset.load(.duration)
            
            print("   üìπ Original duration: \(CMTimeGetSeconds(originalDuration))s")
            
            // Get output directory
            let outputDir = ProcessInfo.processInfo.environment["VIDEOS_DIR"] ?? FileManager.default.currentDirectoryPath
            let outputURL = URL(fileURLWithPath: outputDir).appendingPathComponent("postprocessed_test.mp4")
            
            // Remove existing file if any
            if FileManager.default.fileExists(atPath: outputURL.path) {
                try FileManager.default.removeItem(at: outputURL)
            }
            
            // Create a simple composition (without actual silence removal for this test)
            let composition = AVMutableComposition()
            
            guard let videoTrack = composition.addMutableTrack(withMediaType: .video, preferredTrackID: kCMPersistentTrackID_Invalid),
                  let audioTrack = composition.addMutableTrack(withMediaType: .audio, preferredTrackID: kCMPersistentTrackID_Invalid) else {
                print("   ‚ùå Failed to create tracks")
                return false
            }
            
            // Get source tracks
            let sourceVideoTracks = try await asset.loadTracks(withMediaType: .video)
            let sourceAudioTracks = try await asset.loadTracks(withMediaType: .audio)
            
            guard let sourceVideoTrack = sourceVideoTracks.first else {
                print("   ‚ùå No video track found")
                return false
            }
            
            // Insert and scale tracks
            let timeRange = try await sourceVideoTrack.load(.timeRange)
            try videoTrack.insertTimeRange(timeRange, of: sourceVideoTrack, at: CMTime.zero)
            
            if let sourceAudioTrack = sourceAudioTracks.first {
                try audioTrack.insertTimeRange(timeRange, of: sourceAudioTrack, at: CMTime.zero)
            }
            
            // Apply speed factor
            let speedFactor: Float = 1.15
            let scaledDuration = CMTime(
                value: Int64(Double(timeRange.duration.value) / Double(speedFactor)),
                timescale: timeRange.duration.timescale
            )
            
            videoTrack.scaleTimeRange(
                CMTimeRange(start: CMTime.zero, duration: timeRange.duration),
                toDuration: scaledDuration
            )
            
            if composition.tracks(withMediaType: .audio).count > 0 {
                audioTrack.scaleTimeRange(
                    CMTimeRange(start: CMTime.zero, duration: timeRange.duration),
                    toDuration: scaledDuration
                )
            }
            
            // Preserve transform
            let preferredTransform = try await sourceVideoTrack.load(.preferredTransform)
            videoTrack.preferredTransform = preferredTransform
            
            // Export
            guard let exportSession = AVAssetExportSession(asset: composition, presetName: AVAssetExportPresetHighestQuality) else {
                print("   ‚ùå Failed to create export session")
                return false
            }
            
            exportSession.outputURL = outputURL
            exportSession.outputFileType = .mp4
            exportSession.shouldOptimizeForNetworkUse = false
            
            print("   üöÄ Starting export...")
            try await exportSession.export()
            
            guard exportSession.status == .completed else {
                print("   ‚ùå Export failed with status: \(exportSession.status.rawValue)")
                if let error = exportSession.error {
                    print("      Error: \(error.localizedDescription)")
                }
                return false
            }
            
            print("   ‚úÖ Export successful!")
            print("   üìÅ Output saved to: \(outputURL.path)")
            
            // Verify output
            let outputAsset = AVURLAsset(url: outputURL)
            let outputDuration = try await outputAsset.load(.duration)
            
            print("   üìä Output duration: \(CMTimeGetSeconds(outputDuration))s")
            print("   ‚úì Post-processing pipeline completed")
            
            return true
            
        } catch {
            print("   ‚ùå Test failed: \(error.localizedDescription)")
            return false
        }
    }
}

// Run tests
Task {
    let tests = VideoPostprocessTests()
    await tests.runAllTests()
    exit(0)
}
RunLoop.main.run()
